{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import twitter_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring the Data\n",
    "\n",
    "The sample dataset from NLTK is separated into positive and negative tweets. It contains 5000 positive tweets and 5000 negative tweets exactly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "postive_tweets = twitter_samples.strings(\"positive_tweets.json\")\n",
    "negative_tweets = twitter_samples.strings(\"negative_tweets.json\")\n",
    "\n",
    "print(\"Number of positive tweets: \", len(postive_tweets))\n",
    "print(\"Number of negative tweets: \", len(negative_tweets))\n",
    "print(\"Total number of tweets: \", len(postive_tweets) + len(negative_tweets))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At first, we want to get an understanding of what the data looks like.\n",
    "\n",
    "When you scroll through the samples, you will notice a couple of things that differentiate tweets from normal texts, for example:\n",
    "- usernames, so-called `handles`, e.g `@Lambd2ja`\n",
    "- hashtags, e.g. `#FollowFriday`\n",
    "- emojis and smileys, e.g. ðŸ’ž or `:)`\n",
    "- URLs, e.g. `https://t.co/smyYriipxI\"`\n",
    "- slang words\n",
    "- etc.\n",
    "\n",
    "Make yourself familiar with both the positive and negative tweets!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "postive_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tweet Preprocessing\n",
    "\n",
    "We will be using the `htwgnlp` Python package to preprocess the data.\n",
    "It contains a `preprocessing` module with a `TweetProcessor` class.\n",
    "The boilerplate code for the class is given, as well as some unit tests that describe the desired behavior.\n",
    "\n",
    "Your job will be to implement the `TweetProcessor` class, which is located in `src/htwgnlp/preprocessing.py`\n",
    "The task is completed successfully if all tests for the first assignment pass.\n",
    "You can run the test using the following command:\n",
    "\n",
    "```bash\n",
    "make assignment_1\n",
    "```\n",
    "\n",
    "> As you can check in the `Makefile`, this is will execute `pytest tests/htwgnlp/test_preprocessing.py` under the hood.\n",
    "\n",
    "Let's assume we have the following requirements for the preprocessing pipeline of our tweets:\n",
    "\n",
    "- remove URLs as they are usually shortened and don't add much information to the tweet\n",
    "- remove hashtag symbols `#` but preserve the word of the hashtag since it gives valuable information about the content of the tweet\n",
    "- remove english stopwords\n",
    "- remove standard punctuation, but keep emojis like `:)`\n",
    "- Twitter handles like `@stuartthull` should be removed completely\n",
    "- after preprocessing, it is expected to have the tweet in a tokenized and stemmed for, i.e. a list of words.\n",
    "- for tokenization, you should use [NLTK's `TweetTokenizer`](https://www.nltk.org/api/nltk.tokenize.casual.html#nltk.tokenize.casual.TweetTokenizer)\n",
    "- for stemming, you should use [`NLTK's PorterStemmer`](https://www.nltk.org/api/nltk.stem.porter.html)\n",
    "- Also, tweets should be lowercased and repeated character sequences should not be more than 3, e.g. `looooove` should be transformed to `looove`\n",
    "\n",
    "For more implementation details, please refer to the [docstrings](https://realpython.com/documenting-python-code/#documenting-your-python-code-base-using-docstrings) of the `htwgnlp.preprocessing.TweetProcessor` class.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from htwgnlp.preprocessing import TweetProcessor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code shows the intended usage of the `TweetProcessor` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instatiate a TweetProcessor object\n",
    "processor = TweetProcessor()\n",
    "\n",
    "# we use a selected tweet as an example\n",
    "i = 2277\n",
    "postive_tweets[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each processing step described above is encapsulated in a separate method of the `TweetProcessor` class, and can be called separately. \n",
    "For example, the `remove_urls(tweet: str)` method.\n",
    "\n",
    "If your implementation works correctly, the URL `https://t.co/3tfYom0N1i` should be removed, when you execute the following line:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet = processor.remove_urls(postive_tweets[i])\n",
    "tweet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `remove_hashtag(tweet: str)` method should transform `#sunflowers #favourites #happy #Friday` to `sunflowers favourites happy Friday`\n",
    "\n",
    "> Note that lowercasing comes later in the process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet = processor.remove_hashtags(tweet)\n",
    "tweet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After tokenization, the tweet should be lowercased, and repeated characters as well as twitter handles should be removed.\n",
    "\n",
    "> For this step, make sure to read the docs of [NLTK's `TweetTokenizer`](https://www.nltk.org/api/nltk.tokenize.casual.html#nltk.tokenize.casual.TweetTokenizer)\n",
    "\n",
    "The expected output is a list of tokens. Specifically for our example, at this point, it should be: `['my', 'beautiful', 'sunflowers', 'on', 'a', 'sunny', 'friday', 'morning', 'off', ':)', 'sunflowers', 'favourites', 'happy', 'friday', 'off', 'â€¦']`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet = processor.tokenize(tweet)\n",
    "print(tweet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After removing stopwords: `['beautiful', 'sunflowers', 'sunny', 'friday', 'morning', ':)', 'sunflowers', 'favourites', 'happy', 'friday', 'â€¦']`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet = processor.remove_stopwords(tweet)\n",
    "print(tweet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After removing punctuation, it makes no difference for our example: `['beautiful', 'sunflowers', 'sunny', 'friday', 'morning', ':)', 'sunflowers', 'favourites', 'happy', 'friday', 'â€¦']`\n",
    "\n",
    "> Note that the requirement is to only remove common punctuation, and want to keep emojis like `:)`. However, one could argue if we should want to remove `...` but for this pipeline, let's keep it simple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet = processor.remove_punctuation(tweet)\n",
    "print(tweet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, the last step is stemming. \n",
    "After applying the Porter Stemmer, the tweet should look like this: `['beauti', 'sunflow', 'sunni', 'friday', 'morn', ':)', 'sunflow', 'favourit', 'happi', 'friday', 'â€¦']`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet = processor.stem(tweet)\n",
    "print(tweet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the `process_tweet(tweet: str)` method is a shortcut for all of the above.\n",
    "\n",
    "So after a successful pipeline the input tweet should look like this:\n",
    "\n",
    "```txt\n",
    "['beauti', 'sunflow', 'sunni', 'friday', 'morn', ':)', 'sunflow', 'favourit', 'happi', 'friday', 'â€¦']\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{'Tweet:':<20}{postive_tweets[i]}\")\n",
    "print(f\"{'Processed tweet:':<20}{processor.process_tweet(postive_tweets[i])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When your tests run successfully, this notebook should as well deliver the expected output.\n",
    "\n",
    "Congratulations! ðŸ¥³ðŸš€ You just completed your first assignment!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
